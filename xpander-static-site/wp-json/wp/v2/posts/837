{"id":837,"date":"2025-03-31T14:58:22","date_gmt":"2025-03-31T14:58:22","guid":{"rendered":"https:\/\/xpander.ai\/?p=837"},"modified":"2025-03-31T14:58:23","modified_gmt":"2025-03-31T14:58:23","slug":"how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive","status":"publish","type":"post","link":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/","title":{"rendered":"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive"},"content":{"rendered":"\n<section class=\"wp-block-custom-post-block-content post-block-content\">\n<div class=\"wp-block-group post-block-content__container is-layout-flow wp-block-group-is-layout-flow\">\n<div class=\"wp-block-group post-block-content__sidebar is-layout-flow wp-block-group-is-layout-flow\">\n<div class=\"wp-block-group post-block-content__sidebar-wrapper is-layout-flow wp-block-group-is-layout-flow\"><section class=\"block-acf block-author\" >\r\n\t<div class=\"block-author__container\">\r\n\t\t\t\t\t<figure class=\"block-author__image\">\r\n\t\t\t\t<img loading=\"lazy\" decoding=\"async\" width=\"72\" height=\"72\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-72x72.jpeg\" class=\"attachment-author-image size-author-image\" alt=\"Moriel Pahima\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-72x72.jpeg 72w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-300x300.jpeg 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-150x150.jpeg 150w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-768x768.jpeg 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-503x503.jpeg 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-670x670.jpeg 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-16x16.jpeg 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture-417x417.jpeg 417w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/new-profile-picture.jpeg 800w\" sizes=\"(max-width: 72px) 100vw, 72px\" \/>\t\t\t<\/figure>\r\n\t\t\t\t<p class=\"block-author__info\">\r\n\t\t\t\t\t\t\t<span class=\"block-author__name\">\r\n\t\t\t\t\tMoriel Pahima\t\t\t\t<\/span>\r\n\t\t\t\t\t\t\t\t\t\t<span class=\"block-author__bio\">\r\n\t\t\t\t\tFounding Engineer @ xpander.ai\t\t\t\t<\/span>\r\n\t\t\t\t\t<\/p>\r\n\t<\/div>\r\n<\/section>\r\n\n\n<section class=\"block-acf toc-block alignfull\" >\r\n<div class=\"table-of-contents\">\r\n<\/div>\r\n<\/section>\n\n<section class=\"block-acf block-share\" >\r\n\t<div class=\"block-share__container\">\t\r\n\t\t<div class=\"block-share__icons\">\r\n\t\t\t<a href=\"https:\/\/www.linkedin.com\/shareArticle?mini=true&#038;url=http:\/\/https%3A%2F%2Fxpander.ai%2Fwp-json%2Fwp%2Fv2%2Fposts%2F837\"\r\n\t\t\t\tclass=\"block-share__icon block-share__icon--linkedin\" target=\"_blank\" rel=\"noopener noreferrer\"><\/a>\r\n\t\t\t<a href=\"https:\/\/x.com\/intent\/tweet?url=http:\/\/https%3A%2F%2Fxpander.ai%2Fwp-json%2Fwp%2Fv2%2Fposts%2F837\" class=\"block-share__icon block-share__icon--x\" target=\"_blank\" rel=\"noopener noreferrer\"\r\n\t\t\t><\/a>\r\n\t\t\t<a href=\"https:\/\/www.facebook.com\/sharer\/sharer.php?u=http:\/\/https%3A%2F%2Fxpander.ai%2Fwp-json%2Fwp%2Fv2%2Fposts%2F837\" class=\"block-share__icon block-share__icon--facebook\" target=\"_blank\" rel=\"noopener noreferrer\"\r\n\t\t\t><\/a>\r\n\t\t<\/div>\r\n\t<\/div>\r\n<\/section>\r\n<\/div>\n<\/div>\n\n\n\n<div class=\"wp-block-group post-block-content__text is-layout-flow wp-block-group-is-layout-flow\" style=\"margin-top:0;margin-bottom:0\"><figure class=\"post-block-content__image wp-block-post-featured-image\"><img loading=\"lazy\" decoding=\"async\" width=\"2726\" height=\"1730\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png\" class=\"attachment-post-thumbnail size-post-thumbnail wp-post-image\" alt=\"\" style=\"border-radius:28px;border-style:none;border-width:0px;object-fit:cover;\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png 2726w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-300x190.png 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-1024x650.png 1024w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-768x487.png 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-1536x975.png 1536w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-2048x1300.png 2048w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-503x319.png 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-670x425.png 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-16x10.png 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-657x417.png 657w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-72x46.png 72w\" sizes=\"(max-width: 2726px) 100vw, 2726px\" \/><\/figure>\n\n\n<p>Building AI agents that can <strong>seamlessly interact with real-world tools and data <\/strong>is one of the hardest challenges in modern LLM infrastructure. At xpander.ai, this challenge is our daily bread and butter. We\u2019ve spent countless hours enabling large language models (LLMs) to perform multi-step tasks across SaaS APIs, internal databases, and other systems. When Anthropic open-sourced the <strong>Model Context Protocol (MCP) <\/strong>late last year, we immediately saw its significance. MCP promised a standardized way for AI assistants to connect to the systems where data lives \u2013 a sort of <em>\u201cUSB-C port\u201d <\/em>for AI applications. In theory, it could replace a tangle of bespoke integrations with a <strong>universal, two-way interface<\/strong>.<\/p>\n\n\n\n<p>But theory only takes you so far. <strong>Implementing MCP at scale <\/strong>\u2013 in a production SaaS platform serving enterprise-grade AI agents \u2013 is another story entirely. As a founding engineer at a startup tackling this head-on, I\u2019d like to share our journey adopting MCP and allowing our users to use MCP as a service all across the platform: the architectural decisions, the gritty engineering challenges (from <strong>Server-Sent Events <\/strong>streaming to multi-tenant security), and how we wove MCP into xpander.ai\u2019s agent platform. This post will dive into <strong>how xpander exposes MCP through our agents and interfaces<\/strong>, how we handle tool schemas and validation, and why we even built our own <code>xpander-mcp-remote<\/code> CLI to bridge secure remote connections. Along the way, I\u2019ll contrast MCP with other approaches (like OpenAI\u2019s tool calling and LangChain agents) and explain why we believe MCP is a big deal for the future of AI interoperability.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-base-color has-text-color has-link-color has-regular-font-size wp-elements-f78a087ecfa22459dbe4bf34ab1d48b5\" id=\"What-is-MCP\">What is the Model Context Protocol (MCP) and Why It Matters<\/h2>\n\n\n\n<p>MCP is an <strong>open standard <\/strong>introduced by Anthropic to let AI models connect with external tools, data sources, and environments in a consistent way. Instead of each integration requiring custom code or unique APIs, an AI assistant (like Claude or ChatGPT) can speak a common language to any MCP-compatible service. <em>Think of how USB-C standardized device connections; MCP aspires to do the same for AI-tool integrations (. <\/em>From a technical standpoint, MCP defines a <strong>simple client-server model<\/strong>: AI <strong>hosts <\/strong>(the LLM applications) act as clients that initiate connections, and <strong>MCP servers <\/strong>provide capabilities or data. Communication is done via <strong>JSON-RPC 2.0 <\/strong>messages over a transport channel. In plain English, the AI sends JSON-formatted \u201crequests\u201d to call a tool or fetch some context, and the server returns JSON \u201cresponses\u201d with results (or streams of results). This JSON-RPC design is reminiscent of the Language Server Protocol from the IDE world \u2013 a deliberate inspiration to make AI-tool interactions <strong>composable and standardized <\/strong>across ecosystems.<\/p>\n\n\n\n<p>Why does this matter? Because even the most advanced LLMs are often <strong>trapped in silos<\/strong>. They can\u2019t fetch fresh data from your database or take action in your business software without custom plumbing. Every new integration has historically been an ad-hoc project. MCP aims to <strong>flip that script<\/strong>. With a universal protocol, the community can build and share connectors to databases, SaaS APIs, operating system functions, you name it. An AI agent could maintain context across different tools and datasets more naturally, instead of the fragmented function-call integrations we have today. This has big implications: it could <strong>standardize \u201ctool use\u201d for AI <\/strong>much like HTML standardized content for browsers. In fact, we\u2019re already seeing convergence \u2013 OpenAI announced support for MCP in its own Agents SDK, and Microsoft is building real-world infrastructure on it as well (5). When multiple AI platforms rally around a standard, it\u2019s a sign that <strong>MCP isn\u2019t just hype <\/strong>but an emerging backbone for agent interoperability.<\/p>\n\n\n\n<p>From xpander\u2019s perspective, embracing MCP aligns perfectly with our philosophy of <strong>provider-agnostic, flexible AI integration<\/strong>. We\u2019ve built our platform to avoid vendor lock-in (run with OpenAI, Anthropic, etc.) and to connect agents with any system. An open protocol like MCP is the next logical step: it lets our agents interface with third-party AI assistants on one side and with a plethora of tools on the other, in a uniform way. But to really leverage MCP, we had to get our hands dirty and make it work in practice. Let\u2019s talk about how MCP actually operates under the hood and what it took to implement it in a scalable, secure manner.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"inside-the-MCP-Architecture\">Inside the MCP Architecture: JSON-RPC, Tools, and Streaming<\/h2>\n\n\n\n<p>At its core, the Model Context Protocol is straightforward: <strong>the AI client opens a connection to an MCP server, discovers what \u201ctools\u201d or data the server offers, and starts sending JSON-RPC calls<\/strong>. Each tool is essentially a remote function the AI can invoke. For example, a server might expose a tool like <code>send_email<\/code> or <code>query_database<\/code> with a defined schema for its inputs and outputs. The AI doesn\u2019t need to know the low-level details of how that tool works \u2013 just the name, parameters, and expected result format. This is very analogous to OpenAI\u2019s function calling interface, except that with MCP the <em>implementation of the function lives outside the model\u2019s API <\/em>(it lives in the MCP server).<\/p>\n\n\n\n<p>One key aspect of MCP is that it supports <strong>streaming responses <\/strong>and incremental updates via <strong>Server-Sent Events (SSE) <\/strong>transport. In practice, there are a couple of transport options: for local tools, an LLM might spawn the tool process and communicate over stdin\/stdout (stdio transport). But for remote tools (like a cloud service), the typical method is HTTP + SSE. This works by the client (say Claude Desktop or another agent host) making an <strong>HTTP GET request to a special SSE endpoint <\/strong>on the MCP server to <strong>listen for events<\/strong>, and using a complementary <strong>HTTP POST endpoint to send commands <\/strong>to the server. The persistent SSE connection lets the server push streaming results back to the AI in real-time. For example, if a tool is performing a long-running database query, it can stream partial progress or chunked results to the LLM so the model can start formulating a response without waiting for the entire operation to complete. SSE is unidirectional (server-to-client) for streaming, but combined with the POST channel, it achieves a full two-way communication.<\/p>\n\n\n\n<p><strong>In an MCP session, the typical flow is: <\/strong>the AI client connects and maybe sends an initial \u201cdiscover\u201d or handshake request (JSON-RPC call to list available tools and resources). The server responds with its <strong>capabilities <\/strong>\u2013 essentially a list of tools with their schemas and any other context it provides. From then on, the AI can invoke those tools by sending a JSON-RPC request with the method name (tool name) and parameters. The server executes the tool\u2019s code (which might call an external API or database on behalf of the AI) and returns the result as a JSON-RPC response. If the result is large or the action emits multiple outputs, the server might stream multiple partial responses as SSE events. The protocol also defines some <strong>utility methods <\/strong>like <code>ping<\/code> (health check), <code>cancel<\/code> (to abort a long tool call), and even logging or progress notifications.<\/p>\n\n\n\n<p>All of this provides a structured, controlled way for an AI agent to do things in the world. But making it <strong>robust for real-world use <\/strong>is where the fun begins. At xpander, we needed to integrate MCP into our platform of managed agents and connectors. <\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"challenges\">Several engineering challenges head-on:<\/h2>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Server-Sent Events at Scale: <\/strong>How to manage potentially thousands of long-lived SSE connections reliably.<\/li>\n\n\n\n<li><strong>Multi-Tenancy and Security: <\/strong>How to isolate and secure each client\u2019s tools and data in a multi-user environment.<\/li>\n\n\n\n<li><strong>Tool Schema Registration: <\/strong>How to automatically register and expose our existing \u201ctools\u201d (integrations) via MCP in a way that\u2019s easily consumable by any AI client.<\/li>\n\n\n\n<li><strong>Input\/Output Validation: <\/strong>How to ensure the AI\u2019s JSON-RPC calls are correct and safe, given the notorious tendency of LLMs to hallucinate or format data incorrectly.<\/li>\n\n\n\n<li><strong>Cross-System Orchestration: <\/strong>How to coordinate complex workflows that involve multiple tools or multi-step processes through the MCP interface without confusing the AI or sacrificing reliability.<\/li>\n<\/ul>\n\n\n\n<p>We\u2019ll examine each of these in turn, and explain the design decisions we made to address them.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-large-font-size\" id=\"Challenges-of-Implementing\"><strong>Challenges of Implementing MCP in a Production Platform<\/strong><\/h2>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Streaming\">Handling Streaming with Server-Sent Events (SSE)<\/h2>\n\n\n\n<p>SSE is a lightweight and elegant solution for streaming, but it comes with <strong>practical considerations<\/strong>. In a cloud environment, every SSE client means an open HTTP connection held open indefinitely. When you have a handful of users, that\u2019s no problem; when you have hundreds or thousands, you need to ensure your server and network stack can handle a large number of concurrent open streams. We had to fine-tune our infrastructure (load balancers, timeouts, thread or async handlers) to support many idle-but-open SSE connections. Unlike a typical REST API where each request is quick and then gone, an SSE connection can last hours. We implemented heartbeat mechanisms and careful error handling to make SSE robust \u2013 for instance, <strong>detecting dropped connections and cleaning them up<\/strong>, or having the client auto-reconnect if either side experiences a hiccup. The MCP spec itself emphasizes proper lifecycle management and resource cleanup as a best practice, and we learned why: if you don\u2019t close or reconnect cleanly, you end up with \u201cghost\u201d sessions or resource leaks.<\/p>\n\n\n\n<p>Another challenge was <strong>ensuring timely delivery <\/strong>of events. SSE delivers events in order, which is great, but if a client falls behind (e.g. network slowdown) it could delay subsequent messages. We put in place backpressure handling \u2013 if an SSE client isn\u2019t keeping up consuming events, we may need to slow down or buffer on our side. In extreme cases, we\u2019d rather drop a non-critical notification than block a critical one. These are the kind of nitty- gritty details that don\u2019t show up in the shiny demo of MCP, but absolutely matter for a smooth user experience.<\/p>\n\n\n\n<p>Finally, <strong>streaming adds complexity to multi-step tool calls<\/strong>. Imagine an AI calls a tool that itself triggers sub-operations; we might stream interim results (like partial data from one API before moving to the next). We had to decide how to partition streaming responses in a way that the AI (the client) understands which tool call they belong to. JSON-RPC gives each request an <code>id<\/code> so we can tag events with the corresponding request ID, ensuring even interleaved streams don\u2019t get mixed up. In summary, we treated SSE connections as first- class citizens in our architecture, doing the hardening necessary for cloud scale (as any high-traffic WebSocket or SSE service requires), including timeouts, retries, and graceful fallbacks.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Multi-Tenancy\"><code>Multi-Tenancy<\/code> and Isolation<\/h2>\n\n\n\n<p>xpander.ai is a multi-tenant platform \u2013 each user (or team) may have their own set of agents, connectors, and data. Exposing those via MCP meant we needed a strategy to <strong>securely segregate each tenant\u2019s MCP endpoints<\/strong>. We obviously <strong>cannot have a single MCP<\/strong> <strong>server instance serve tools from multiple customer accounts <\/strong>without strong isolation, or we\u2019d risk a privacy disaster. Our approach was to <strong>spin up logical MCP \u201cservers\u201d on a per- agent or per-integration basis<\/strong>, each identified by a unique URL containing an embedded API key or token. In practice, when you configure an integration (say a Slack connector) in xpander and enable MCP, our backend generates an <strong>MCP entry point URL <\/strong>that looks something like:<\/p>\n\n\n\n<pre class=\"wp-block-code\"><code><code>https:\/\/mcp.xpander.ai\/&lt;AGENT_OR_INTERFACE_ID>\/&lt;SECRET_TOKEN><\/code><\/code><\/pre>\n\n\n\n<p>This URL is essentially the address of your personal MCP server for that integration. We include a secret token in it (a long random string or API key) that the server uses to authenticate the caller. <\/p>\n\n\n\n<p><strong>Possession of that URL is what grants access<\/strong>, so we treat it like a password \u2013 it\u2019s shown to you once in our UI when you set up the integration, and you should keep it safe (The MCP URL contains your API key, so never share it publicly. Treat it as a sensitive credential). When an AI client connects via that URL, we map it to your specific tools and data on the backend.<\/p>\n\n\n\n<p>With this design, <strong>each user and each agent sees only their own connectors and actions<\/strong>. Even though behind the scenes many of those MCP endpoints might be served by the same cluster of servers, our software isolates their contexts completely. It\u2019s analogous to how a cloud database service might give you a unique connection string for your database \u2013 even if it\u2019s on a shared host, only you can access your slice. We also leverage tenant IDs in our logging and monitoring, so we can trace any request back to the originating account for auditing. This was non-trivial to implement because the MCP protocol itself is agnostic about multi-tenancy; it just defines the message passing. We had to layer our own <strong>authentication and routing <\/strong>on top of it. Thankfully, the <strong>MCP spec is adding a formal OAuth 2.1-based authorization framework in the latest revision (5)<\/strong>, which we plan to adopt when clients support it and it will become stable. For now, the unique URL token approach, combined with HTTPS and our backend checks, provides the security our users need.<\/p>\n\n\n\n<p>Another aspect of multi-tenancy is <strong>rate limiting and abuse prevention<\/strong>. If one user\u2019s agent code goes haywire and starts spamming tool calls, we don\u2019t want it to degrade service for others. We implemented per-token rate limits on MCP requests and put safeguards so one user can\u2019t exhaust all server-side threads with extremely long-running tasks. These are the kinds of protections that an enterprise-ready platform needs to have in place when exposing something like MCP to the open world.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Tool-Schema\">Tool Schema Registration and Versioning<\/h2>\n\n\n\n<p>For MCP to be useful, the AI client needs to know <strong>what tools are available and how to call them<\/strong>. In MCP\u2019s terminology, this is often handled by the server advertising its <strong>capabilities<\/strong> <strong>or an openRPC schema<\/strong>. In our case, xpander already had the concept of <strong>Agentic Interfaces (tools\/connectors) <\/strong>each defined by an internal schema (very similar to an OpenAI function spec). For example, our Gmail connector has an action <code>send_email<\/code> <code>to<\/code>, <code>subject<\/code>, <code>body<\/code>, etc., each with certain types or allowed formats. Adapting them to MCP was relatively straightforward: we translate our internal schema format into the JSON schema syntax expected by MCP JSON-RPC. Essentially, when an AI client asks our MCP endpoint \u201cwhat methods do you have?\u201d, we respond with a list of methods and their parameter schema, description, etc., drawn from the same definitions that power our platform\u2019s function calling. This dual-use of schemas ensures <strong>consistency <\/strong>\u2013 whether an agent is running inside xpander or an AI is calling via MCP, the definition of <code>send_email<\/code> or <code>create_ticket<\/code> is the same.<\/p>\n\n\n\n<p>That said, maintaining these schemas over time is a chore. APIs change, we improve descriptions, add new optional parameters, deprecate others. We built a <strong>tool registry<\/strong> <strong>system <\/strong>internally where each integration\u2019s schema is versioned. When we deploy an update to a connector (say we add a new action or change a field), the MCP server for that connector can advertise a new version in its capability response. We decided to keep things simple for now: our MCP endpoints always expose the <strong>latest <\/strong>version of a tool\u2019s capabilities, under the assumption that both our backend and the AI using it should be kept up-to-date. (If a breaking change occurs, we coordinate it as a product update to users.) In the future, we may leverage the MCP spec\u2019s version negotiation features so that clients could specify a version or handle compatibility more gracefully.<\/p>\n\n\n\n<p>One interesting nuance was how to <strong>present complex tools to the LLM<\/strong>. Some of our integrations are relatively simple (one-call actions), but others are complex sequences. For example, consider a database query tool where the AI first needs to call a <code>list_tables<\/code> method, then a <code>query_table<\/code> We have to expose all those sub-methods. We make sure to provide helpful descriptions and even usage examples in the metadata so that the model can figure out the right sequence. Experience taught us that <strong>the quality of tool<\/strong> <strong>descriptions and schemas directly impacts the model\u2019s success in using them<\/strong>. A small ambiguity can lead the LLM to construct an invalid payload. Even with clear schemas, LLMs sometimes produce <strong>imperfect API calls <\/strong>\u2013 which brings us to validation.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Validation\">Input Validation and Error Handling<\/h2>\n\n\n\n<p class=\"has-regular-font-size\">Anyone who has tried OpenAI\u2019s function calling or similar will know that models aren\u2019t infallible in formatting their outputs. They might omit a required field, use an incorrect data type, or misunderstand an error message. We saw the same with MCP. The difference with MCP is that the execution of the tool is happening outside the model\u2019s context (in our server), so <strong>we must validate the request payloads carefully before executing <\/strong>anything. Our MCP server performs a multi-layer validation on every incoming JSON-RPC request: first it checks <strong>JSON schema validity <\/strong>(are all required parameters present? do types match? enums within allowed set, etc.). This catches the obvious mistakes. But we didn\u2019t stop there. We also added <strong>semantic validation <\/strong>where appropriate. For instance, if the tool is <code>create_notion_page<\/code> and the model provided <code>property_name<\/code> that doesn\u2019t actually exist in the target Notion database, we can detect that by a pre-flight check against the actual system (or a cached schema of the user\u2019s Notion DB) and return a clear error to the AI before even attempting the call. This is important because the model might produce something that is <em>technically <\/em>well-formed JSON yet <em>semantically <\/em>incorrect for the task. As we noted in an earlier blog post, even a perfectly structured output can fail if the content doesn\u2019t match the real API\u2019s expectations (e.g. using <code>\"title\"<\/code> instead of the actual field name <code>\"name\"<\/code> in a Notion API call) (4). Our job on the MCP server side is to catch those and signal back to the model, ideally with a helpful error message.<\/p>\n\n\n\n<p class=\"has-regular-font-size\">We leverage JSON-RPC\u2019s error response format to do this. If validation fails, we return an error object with a message explaining the issue. For example, <em>\u201cError: \u2018title\u2019 is not a recognized field; did you mean \u2018name\u2019?\u201d <\/em>in the Notion scenario. The nice thing is LLMs are pretty good at reading error messages and adjusting their next attempt accordingly (Claude and GPT-4 certainly are). By iterating this way, the AI can usually self-correct and succeed on the second try. This dynamic is crucial for letting the AI figure out how to use complex tools \u2013 it\u2019s not unlike a human learning an API by seeing error responses.<\/p>\n\n\n\n<p class=\"has-regular-font-size\">On the output side, validation is also important. We ensure the data we send back conforms to the schema we promised. This might involve sanitizing or transforming results from an external API. For example, if an API returns a numeric code where our schema says <code>status: \"success\" | \"fail\"<\/code>, we translate that code into one of the expected strings so the model only sees the format it was told to expect. Consistency here means the model doesn\u2019t get confused by out-of-schema surprises. And if for some reason our tool encounters an unexpected situation (e.g. a network timeout contacting a third-party service), we also package that as a proper JSON-RPC error so that the model knows the tool didn\u2019t complete. This avoids a class of issues where the model might be left waiting or guessing. Overall, rigorous validation and error handling have been key to making MCP usable in practice. It turns the wild, unconstrained outputs of an LLM into a disciplined conversation between the AI and our tools. In effect, we\u2019re providing the <strong>guardrails <\/strong>that keep the agent from driving off the road when it comes to tool use. The result is more reliable autonomous agents \u2013 something we\u2019ve quantified before (our structured approach improved multi-step success rates dramatically)<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Orchestrating\">Orchestrating Cross-System Workflows<\/h2>\n\n\n\n<p>A major appeal of xpander\u2019s platform is that an agent can orchestrate <strong>multi-step workflows involving several different tools<\/strong>. For instance, <em>\u201cWhen a new lead appears in Salesforce, cross-reference it with our product database, then send a Slack alert and create a task in Asana.\u201d <\/em>That might involve 7-10 distinct API calls across systems. Now, if you give an LLM all those tools via MCP and just say \u201chave at it,\u201d it might figure it out\u2026 or it might flounder. One of the hard truths of autonomous agents is that <strong>the more tools you provide, the more combinatorial complexity the poor model has to reason about<\/strong>. We\u2019ve found that beyond a handful of tools, success rates drop sharply (<a href=\"#sources\">4<\/a>). So, how do we enable cross-system magic without overloading the AI?<\/p>\n\n\n\n<p>Our solution inside xpander has been to introduce an <strong>Agent Graph System (AGS) <\/strong>\u2013 essentially a directed graph that can orchestrate calls in a controlled fashion. Think of it as a smart wrapper that can guide the LLM: at a given step, only certain tools or sequences are allowed, and state from previous steps is stored and passed along. When exposing capabilities via MCP, we have two modes:<\/p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><img loading=\"lazy\" decoding=\"async\" width=\"4\" height=\"4\" src=\"\"><strong>Expose each tool individually<\/strong>: This is the straightforward approach where the AI (e.g. Claude) sees \u201cSlack.send_message\u201d, \u201cSalesforce.get_lead\u201d, \u201cAsana.create_task\u201d as separate actions. The AI can decide to call them in whatever order. This maximizes flexibility but as mentioned, can be brittle if the sequence is complex.<\/li>\n\n\n\n<li>Exposing <strong>entire agents as MCP servers <\/strong>is a powerful pattern. In xpander, you can indeed treat a whole agent (with its multiple steps and logic) as a single MCP endpoint. This means the AI client doesn\u2019t need to micromanage each sub-tool; it delegates a chunk of work to xpander\u2019s orchestrator. We carefully document to the user (and by extension to the LLM via descriptions) what that one \u201cmega-tool\u201d will do. For instance:<em> &#8220;<code>handle_new_deal<\/code>: automates the new lead processing by cross-checking internal DB and notifying Sales via Slack.\u201d <\/em>The LLM can then decide if and when to use that capability, rather than juggling 3-4 discrete calls on its own.<\/li>\n<\/ul>\n\n\n\n<p>We still support the fine-grained approach when needed (single MCP Server and cherry-picking API operations). But having the option to <strong>encapsulate multi-step workflows into a domain specific agent <\/strong>has been a game changer for reliability. It\u2019s very analogous to how high-level APIs increase success by doing more behind the scenes. We\u2019re basically raising the abstraction level of the tools when appropriate and still keeping the autonomy of the AI Agent. And thanks to MCP\u2019s flexibility, whether we present 10 separate tools or 1 composite tool, it\u2019s just a matter of what we advertise in the server\u2019s capabilities. The protocol doesn\u2019t constrain it \u2013 we do, based on what yields better outcomes.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"MCP-Integration\">xpander.ai\u2019s MCP Integration demo: Agents, Interfaces, and Entry Points<\/h2>\n\n\n\n<figure class=\"wp-block-video\"><video controls src=\"https:\/\/assets.xpanderai.io\/vidoes\/release-notes\/mcp-support.mp4\"><\/video><\/figure>\n\n\n\n<p>With the challenges addressed (or at least mitigated), how does all this come together in xpander.ai\u2019s product? Let\u2019s walk through what happens when an xpander user wants to use MCP:<\/p>\n\n\n\n<ol class=\"wp-block-list\">\n<li><strong>Enabling MCP for an Agent or Integration: <\/strong>In our web console, the user can navigate to their <strong>Agentic Interfaces <\/strong>settings. Here they see all the connectors (integrations) they have set up \u2013 e.g. Gmail, LinkedIn, Slack, HubSpot, internal APIs, etc. Each of these has an option to \u201cMCP Configuration\u201d. We also allow enabling MCP on an entire agent (which might encompass multiple tools). When they enable it, we generate the unique <strong>MCP endpoint URL <\/strong>(entry point) for that specific interface or agent. This is shown to the user, and they are instructed to plug it into their chosen AI client. For example, if using Claude Desktop, they\u2019d add an entry in the <code>claude_desktop_config.json<\/code> with a name and the command to run our CLI with that URL. If using another client (say an IDE like Cursor or Visual Studio Code with an AI plugin), a similar config is added.<\/li>\n\n\n\n<li>Using <code>xpander-mcp-remote<\/code> CLI &#8211; Today, many AI clients (Claude Desktop, Cursor, etc.) assume MCP servers will run locally. They typically want to <strong>execute a command <\/strong>on your machine that starts the MCP server. Obviously, our xpander MCP server is running in the cloud, not on your laptop. <code>xpander-mcp-remote<\/code> is a small Node.js CLI tool (available via <code>npx<\/code>) that acts as a <strong>bridge between<\/strong> <strong>local and remote<\/strong>. When Claude Desktop launches it for, say, the \u201cslack\u201d integration, the CLI connects to <code>https:\/\/mcp.xpander.ai\/your-slack-url<\/code> using the SSE transport and then presents a local stdio interface to Claude. In essence, to Claude it looks like it\u2019s talking to a local process (over stdio), but in reality that process is piping everything over the internet to xpander\u2019s servers. This trick allows existing MCP clients (which don\u2019t yet natively support remote HTTP+SSE with auth) to connect to cloud-hosted tools (mcp-remote &#8211; npm).<\/li>\n<\/ol>\n\n\n\n<p>The need for<code> xpander-mcp-remote<\/code> arose from a practical gap: <strong>MCP was designed with web connectivity in mind, but early implementations favored local use <\/strong>for security reasons. Running connectors locally has advantages \u2013 your secrets stay on your machine, no external server needed \u2013 but it\u2019s not scalable for us as a SaaS (and it\u2019s a pain for users to set up dozens of tools on each device). By using our remote endpoints, users let us handle the heavy parts on our cloud, and the CLI just handles the secure forwarding. Importantly, the CLI is stateless and doesn\u2019t contain any credentials beyond the URL you feed it. That URL has an embedded token which it uses to authenticate to our server over TLS. The CLI does not log or share that token anywhere else. In fact, it\u2019s a tiny wrapper around the official MCP client SDK \u2013 essentially just enough code to open the SSE channel and pass bytes back and forth. Think of it like <code>ssh -L<\/code> port forwarding, but for MCP JSON streams. <\/p>\n\n\n\n<p>Under the hood, Claude might call the Slack.read_channel tool (via the Slack MCP server) to get messages, then call Gmail.send_email (via the Gmail MCP server) \u2013 both calls are handled by xpander on the backend, using the user\u2019s already-configured auth for Slack and Gmail. Because the user had linked Slack and Gmail accounts in xpander beforehand, Claude doesn\u2019t need to ask for any OAuth permissions \u2013 xpander acts as the trusted broker. (As our docs note, if you\u2019ve set up your Gmail connector in xpander, you can immediately use it through Claude with no additional auth steps. That\u2019s a big win for user experience.)<\/p>\n\n\n\n<p>This is how Cursor will load all the tools:<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"2348\" height=\"1054\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5.png\" alt=\"\" class=\"wp-image-869\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5.png 2348w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-300x135.png 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-1024x460.png 1024w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-768x345.png 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-1536x689.png 1536w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-2048x919.png 2048w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-503x226.png 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-670x301.png 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-16x7.png 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-657x295.png 657w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-5-72x32.png 72w\" sizes=\"(max-width: 2348px) 100vw, 2348px\" \/><\/figure>\n\n\n\n<p>We can now use the chat window to ask Cursor &#8220;create new DB called weekly todo and add few items to it&#8221;<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"2084\" height=\"1764\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7.png\" alt=\"\" class=\"wp-image-871\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7.png 2084w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-300x254.png 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-1024x867.png 1024w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-768x650.png 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-1536x1300.png 1536w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-2048x1734.png 2048w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-503x426.png 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-670x567.png 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-16x14.png 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-493x417.png 493w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-7-72x61.png 72w\" sizes=\"(max-width: 2084px) 100vw, 2084px\" \/><\/figure>\n\n\n\n<p>Although it didn&#8217;t work out in the example, because Cursor can&#8217;t always to multi-step correctly, this approach of connecting tools can work for other use-cases, but we see that that Agent as MCP is now producing the most value. <\/p>\n\n\n\n<p>In xpander.ai you can define API-Rules, in this example, we can enforce that the above error will never happen, by placing the &#8220;Search Pages and Database&#8221; in the first state like the below image <\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"2610\" height=\"974\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6.png\" alt=\"\" class=\"wp-image-870\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6.png 2610w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-300x112.png 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-1024x382.png 1024w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-768x287.png 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-1536x573.png 1536w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-2048x764.png 2048w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-503x188.png 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-670x250.png 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-16x6.png 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-657x245.png 657w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/image-6-72x27.png 72w\" sizes=\"(max-width: 2610px) 100vw, 2610px\" \/><\/figure>\n\n\n\n<p>We can ask Claude and Cursor for the same , and this time it will send natural language to the agent, instead of guessing the right order.<\/p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"2058\" height=\"1284\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB.png\" alt=\"\" class=\"wp-image-872\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB.png 2058w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-300x187.png 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-1024x639.png 1024w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-768x479.png 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-1536x958.png 1536w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-2048x1278.png 2048w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-503x314.png 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-670x418.png 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-16x10.png 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-657x410.png 657w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/21F00DD2-CDBE-4F80-83EE-6BFAB48FFBBB-72x45.png 72w\" sizes=\"(max-width: 2058px) 100vw, 2058px\" \/><\/figure>\n\n\n\n<h1 class=\"wp-block-heading has-large-font-size\">Result : AI Agents are now available as MCP<\/h1>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"554\" src=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-1024x554.png\" alt=\"\" class=\"wp-image-875\" srcset=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-1024x554.png 1024w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-300x162.png 300w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-768x416.png 768w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-1536x831.png 1536w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-2048x1108.png 2048w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-503x272.png 503w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-670x363.png 670w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-16x9.png 16w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-657x356.png 657w, https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/6B80E2CA-AA12-4F62-A92E-2D99A0DD9D90-1-72x39.png 72w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Broader-Tooling-Ecosystem\">MCP in the Broader Tooling Ecosystem: How xpander\u2019s Approach Differs<\/h2>\n\n\n\n<p>Before we wrap up, it\u2019s worth positioning MCP and xpander\u2019s approach in context with other agent toolcalling systems out there. We often get asked: <em>\u201cHow is this different from OpenAI functions or LangChain or Azure\u2019s new Agents?\u201d <\/em>The truth is, <strong>we\u2019re all trying to solve<\/strong> <strong>similar problems<\/strong>, but with different scopes and philosophies:<\/p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>OpenAI Function Calling vs MCP: <\/strong>OpenAI\u2019s function calling (and its newer \u201cAgents\u201d SDK) is a proprietary mechanism that lets GPT models call developer-defined functions. It\u2019s powerful, but it\u2019s <em>tied to OpenAI\u2019s ecosystem<\/em>. MCP, by contrast, is <strong>model-agnostic and vendor-neutral<\/strong>. It can be used by Claude, by open-source LLMs, by ChatGPT (now that OpenAI is on board), or any future AI system. In a sense, OpenAI function calling is like building a custom adapter for each model, whereas MCP is trying to be a <strong>universal adapter<\/strong>. At xpander, we support both \u2013 internally we use function calling for models that have it (to get initial tool selection by the model), but we use MCP as the external interface so that <em>any model <\/em>(including ones that don\u2019t have native function calling) can interact with our tools. One neat alignment: OpenAI\u2019s Agents and Anthropic\u2019s Claude are converging on supporting MCP directly, which validates our decision to integrate MCP early.<\/li>\n\n\n\n<li><strong>LangChain\/LlamaIndex vs MCP: <\/strong>LangChain, Semantic Kernel, and similar frameworks are libraries that help developers <em>build agents and tool workflows in code<\/em>. They\u2019re fantastic for prototyping and custom agent logic. However, they don\u2019t define a wire protocol; they run in-process. You might use LangChain to script an agent that calls some Python functions. But if you want ChatGPT or Claude to use those same functions, there wasn\u2019t a standard way \u2013 you\u2019d have to host them and maybe expose as an API or plugin. MCP fills that gap by providing the <strong>standard interface<\/strong>. In fact, one way to view xpander.ai is as a hosted LangChain++ with superpowers: we let you bring your own agent logic (we\u2019re compatible with frameworks like Smol, LangGraph, etc.), and then we provide the scaling, monitoring, and <strong>MCP integration <\/strong>out-of-the-box. Instead of you standing up a server for your LangChain agent, xpander does it and speaks MCP. So, we see these frameworks as complementary. Our approach differs mainly in that we emphasize <strong>managed reliability and ease of integration <\/strong>over DIY coding. For example, our Agent Graph System (AGS) is a response to the unreliability of purely LLM-driven planning \u2013 it\u2019s more opinionated than LangChain\u2019s planner, but yields higher success on complex tasks. We then expose those orchestrated capabilities via MCP so any LLM can tap into them. In short: LangChain is about building an agent from scratch, whereas xpander is about configuring and deploying agents quickly (and now, connecting them via MCP anywhere).<\/li>\n\n\n\n<li><strong>Azure OpenAI Plugins\/Agents vs xpander MCP: <\/strong>Azure has announced an \u201cAI Agent\u201d service and things like Copilot Chat plugins. Those are fairly analogous to OpenAI\u2019s approach \u2013 tightly integrated into Microsoft\u2019s ecosystem (Graph, Office 365, etc.). They also support MCP on some level (Microsoft even contributed an MCP server for web browsing (5)). The difference is that xpander is an independent platform that can hook into <em>both <\/em>Microsoft and non-Microsoft tools, <em>both <\/em>OpenAI and Anthropic models, etc. We are aiming for <strong>maximum flexibility<\/strong>. By supporting MCP, we even make it possible for a Microsoft Copilot to call an xpander-hosted tool, or for an Anthropic Claude to call an Azure service, through the same protocol. It\u2019s all about interoperability.<\/li>\n<\/ul>\n\n\n\n<p>At the end of the day, what truly sets xpander\u2019s approach apart is our focus on the <strong>full lifecycle of agent operations<\/strong>. It\u2019s not enough to just connect a model to a tool; you need to manage state, monitor usage, handle errors gracefully, log and debug agent decisions, and ensure security in a multi-user environment. We built all that into the platform from day one. MCP is simply a new interface on top of these robust internals. We were early adopters (likely among the first startups to roll out MCP support in a production product) and that gave us a head start to influence its use in real scenarios. We also contribute feedback to the open MCP community \u2013 for example, our experience with <code>xpander-mcp-remote<\/code> and multi-tenant auth is valuable input as the standards evolve.<\/p>\n\n\n\n<h2 class=\"wp-block-heading has-regular-font-size\" id=\"Conclusion\">The Road Ahead for MCP and Agentic AI<\/h2>\n\n\n\n<p>Integrating the Model Context Protocol into xpander.ai has been an <strong>exciting journey at the cutting edge of AI engineering<\/strong>. We took an emerging standard and, in a matter of weeks, <strong>made it real for our users <\/strong>\u2013 bridging cloud and local, SaaS and on-prem, human and AI. Along the way we solved gnarly problems that don\u2019t often get talked about in glossy tech announcements: keeping SSE connections stable, making sure one user\u2019s AI doesn\u2019t snoop on another\u2019s data, taming LLM output to fit strict schemas, and orchestrating multi-tool dances without missing a step. The result is that xpander\u2019s agents can now operate wherever our users want them \u2013 whether that\u2019s inside a Claude conversation window, a VSCode plugin, a Slack chatbot, or a custom UI \u2013 all thanks to the common language of MCP.<\/p>\n\n\n\n<p>Why does this matter in the big picture? Because as AI agents become more commonplace, <strong>interoperability and reliability are key<\/strong>. No one wants to be locked into a single vendor or rewrite all their integrations for each new AI platform. By backing open protocols, we ensure that the AI we build today will work with the AI platforms of tomorrow. MCP is rapidly gaining traction (the spec just got a major update to improve security and real-time interactions), and we expect it to become a default component in the AI developer toolkit. In practical terms, this means an xpander user might soon connect a ChatGPT Enterprise instance to xpander with the same ease we connected Claude \u2013 and the underlying agents and tools won\u2019t need any changes to accommodate that.<\/p>\n\n\n\n<p>From the perspective of a startup founder-engineer, I also appreciate how MCP <strong>lowers the barrier for innovation<\/strong>. It encourages a plugin-like ecosystem for AI capabilities. We can write an MCP server for a new service once, and any MCP-compatible AI can use it. We\u2019ve done this for numerous connectors (some we haven\u2019t even officially announced yet). It\u2019s reminiscent of the early days of web APIs \u2013 those who embraced RESTful standards saw their services integrated far and wide. We think a similar wave is happening for AI agents, and we\u2019re positioning xpander.ai to ride that wave, if not help steer it.<\/p>\n\n\n\n<h5 class=\"wp-block-heading\" id=\"sources\">Further read and links <\/h5>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Anthropic, <em>\u201cIntroducing the Model Context Protocol\u201d <\/em>\u2013 Overview of MCP as an open standard for connecting AI to data sources. <a href=\"https:\/\/www.anthropic.com\/news\/model-context-protocol#%3A~%3Atext%3DMCP%20addresses%20this%20challenge%2Cto%20the%20data%20they%20need\">Introducing the Model Context Protocol \\<\/a> <a href=\"https:\/\/www.anthropic.com\/news\/model-context-protocol#%3A~%3Atext%3DMCP%20addresses%20this%20challenge%2Cto%20the%20data%20they%20need\">Anthropic<\/a><\/li>\n\n\n\n<li>Model Context Protocol Specification \u2013 Technical details on MCP architecture, JSON- RPC message format, and SSE transport. <a href=\"https:\/\/modelcontextprotocol.io\/docs\/concepts\/transports#%3A~%3Atext%3DServer\">Transports &#8211; Model Context Protocol<\/a><br><a href=\"https:\/\/spec.modelcontextprotocol.io\/specification\/2025-03-26\/#%3A~%3Atext%3DThe%20protocol%20uses%20JSON%2Cmessages%20to%20establish%20communication%20between\">Model Context Protocol specification<\/a><\/li>\n\n\n\n<li>xpander.ai Documentation \u2013 Guide on integrating xpander\u2019s agent interfaces with MCP and using the <code>xpander-mcp-remote<\/code> CLI.<a href=\"https:\/\/docs.xpander.ai\/docs\/05-human-interfaces\/04-mcp#%3A~%3Atext%3D%7B%20%2Curl%2F%22\">Model Context Protocol (MCP) Integration<\/a><\/li>\n\n\n\n<li>xpander.ai Engineering Blog \u2013 Discussion of multi-step agent challenges and the need for robust tool schemas and validation. <br><a href=\"https:\/\/xpander.ai\/2024\/11\/20\/announcing-agent-graph-system\/#%3A~%3Atext%3DAI%2Cstill%20result%20in%20an%20error\">Announcing Agent Graph System<\/a><\/li>\n\n\n\n<li>VentureBeat, <em>\u201cMCP updated \u2014 here\u2019s why it\u2019s a big deal\u201d <\/em>\u2013 Recent news on MCP spec updates (OAuth, improved transport) and industry adoption by OpenAI and Microsoft.<br><a href=\"https:\/\/venturebeat.com\/ai\/the-open-source-model-context-protocol-was-just-updated-heres-why-its-a-big-deal\/#%3A~%3Atext%3D%2A%20OAuth%202.1%2Cand%20reasoning%20by%20AI%20agents\">The open source Model Context Protocol was just updated <\/a><\/li>\n<\/ol>\n<\/div>\n<\/div>\n<\/section>\n","protected":false},"excerpt":{"rendered":"","protected":false},"author":7,"featured_media":819,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"_acf_changed":false,"footnotes":""},"categories":[34,21],"tags":[22,23,33,25,29,28,47,48,24],"class_list":["post-837","post","type-post","status-publish","format-standard","has-post-thumbnail","hentry","category-ai-platform-engineering","category-announcements","tag-ai","tag-ai-agents","tag-ai-platform-engineering","tag-function-calling","tag-gen-ai","tag-genai","tag-mcp","tag-multi-agents","tag-xpander-ai"],"acf":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO plugin v25.1 - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive - xpander.ai | Backend-as-a-Service for AI Agents<\/title>\n<meta name=\"description\" content=\"Explore how 2025 marks a groundbreaking shift as AI starts building and managing its own intelligent agents, revolutionizing automation and innovation.\" \/>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive - xpander.ai | Backend-as-a-Service for AI Agents\" \/>\n<meta property=\"og:description\" content=\"Explore how 2025 marks a groundbreaking shift as AI starts building and managing its own intelligent agents, revolutionizing automation and innovation.\" \/>\n<meta property=\"og:url\" content=\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/\" \/>\n<meta property=\"og:site_name\" content=\"xpander.ai | Backend-as-a-Service for AI Agents\" \/>\n<meta property=\"article:published_time\" content=\"2025-03-31T14:58:22+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2025-03-31T14:58:23+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-1024x650.png\" \/>\n\t<meta property=\"og:image:width\" content=\"1024\" \/>\n\t<meta property=\"og:image:height\" content=\"650\" \/>\n\t<meta property=\"og:image:type\" content=\"image\/png\" \/>\n<meta name=\"author\" content=\"Moriel Pahima\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"Moriel Pahima\" \/>\n\t<meta name=\"twitter:label2\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"26 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"WebPage\",\"@id\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/\",\"url\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/\",\"name\":\"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive - xpander.ai | Backend-as-a-Service for AI Agents\",\"isPartOf\":{\"@id\":\"https:\/\/xpander.ai\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#primaryimage\"},\"image\":{\"@id\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#primaryimage\"},\"thumbnailUrl\":\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png\",\"datePublished\":\"2025-03-31T14:58:22+00:00\",\"dateModified\":\"2025-03-31T14:58:23+00:00\",\"author\":{\"@id\":\"https:\/\/xpander.ai\/#\/schema\/person\/a400b76c595b350b1bc258573ffdf6a7\"},\"description\":\"Explore how 2025 marks a groundbreaking shift as AI starts building and managing its own intelligent agents, revolutionizing automation and innovation.\",\"breadcrumb\":{\"@id\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/\"]}]},{\"@type\":\"ImageObject\",\"inLanguage\":\"en-US\",\"@id\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#primaryimage\",\"url\":\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png\",\"contentUrl\":\"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png\",\"width\":2726,\"height\":1730},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/xpander.ai\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive\"}]},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/xpander.ai\/#website\",\"url\":\"https:\/\/xpander.ai\/\",\"name\":\"xpander.ai | Backend-as-a-Service for AI Agents\",\"description\":\"Backend-as-a-Service for AI Agents\",\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/xpander.ai\/?s={search_term_string}\"},\"query-input\":{\"@type\":\"PropertyValueSpecification\",\"valueRequired\":true,\"valueName\":\"search_term_string\"}}],\"inLanguage\":\"en-US\"},{\"@type\":\"Person\",\"@id\":\"https:\/\/xpander.ai\/#\/schema\/person\/a400b76c595b350b1bc258573ffdf6a7\",\"name\":\"Moriel Pahima\",\"image\":{\"@type\":\"ImageObject\",\"inLanguage\":\"en-US\",\"@id\":\"https:\/\/xpander.ai\/#\/schema\/person\/image\/\",\"url\":\"https:\/\/secure.gravatar.com\/avatar\/776a070d09f269ef3d078f9a8041dc92?s=96&d=mm&r=g\",\"contentUrl\":\"https:\/\/secure.gravatar.com\/avatar\/776a070d09f269ef3d078f9a8041dc92?s=96&d=mm&r=g\",\"caption\":\"Moriel Pahima\"},\"description\":\"Founding Engineer @ xpander.ai\",\"sameAs\":[\"http:\/\/www.xpander.ai\"],\"url\":\"https:\/\/xpander.ai\/author\/moriel\/\"}]}<\/script>\n<!-- \/ Yoast SEO plugin. -->","yoast_head_json":{"title":"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive - xpander.ai | Backend-as-a-Service for AI Agents","description":"Explore how 2025 marks a groundbreaking shift as AI starts building and managing its own intelligent agents, revolutionizing automation and innovation.","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/","og_locale":"en_US","og_type":"article","og_title":"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive - xpander.ai | Backend-as-a-Service for AI Agents","og_description":"Explore how 2025 marks a groundbreaking shift as AI starts building and managing its own intelligent agents, revolutionizing automation and innovation.","og_url":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/","og_site_name":"xpander.ai | Backend-as-a-Service for AI Agents","article_published_time":"2025-03-31T14:58:22+00:00","article_modified_time":"2025-03-31T14:58:23+00:00","og_image":[{"width":1024,"height":650,"url":"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp-1024x650.png","type":"image\/png"}],"author":"Moriel Pahima","twitter_card":"summary_large_image","twitter_misc":{"Written by":"Moriel Pahima","Est. reading time":"26 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"WebPage","@id":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/","url":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/","name":"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive - xpander.ai | Backend-as-a-Service for AI Agents","isPartOf":{"@id":"https:\/\/xpander.ai\/#website"},"primaryImageOfPage":{"@id":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#primaryimage"},"image":{"@id":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#primaryimage"},"thumbnailUrl":"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png","datePublished":"2025-03-31T14:58:22+00:00","dateModified":"2025-03-31T14:58:23+00:00","author":{"@id":"https:\/\/xpander.ai\/#\/schema\/person\/a400b76c595b350b1bc258573ffdf6a7"},"description":"Explore how 2025 marks a groundbreaking shift as AI starts building and managing its own intelligent agents, revolutionizing automation and innovation.","breadcrumb":{"@id":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#primaryimage","url":"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png","contentUrl":"https:\/\/xpander.ai\/wp-content\/uploads\/2025\/03\/cover-mcp.png","width":2726,"height":1730},{"@type":"BreadcrumbList","@id":"https:\/\/xpander.ai\/2025\/03\/31\/how-xpander-ai-embraces-the-model-context-protocol-in-practice-an-engineering-deep-dive\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/xpander.ai\/"},{"@type":"ListItem","position":2,"name":"How xpander.ai Embraces the Model Context Protocol in Practice: An Engineering Deep-Dive"}]},{"@type":"WebSite","@id":"https:\/\/xpander.ai\/#website","url":"https:\/\/xpander.ai\/","name":"xpander.ai | Backend-as-a-Service for AI Agents","description":"Backend-as-a-Service for AI Agents","potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/xpander.ai\/?s={search_term_string}"},"query-input":{"@type":"PropertyValueSpecification","valueRequired":true,"valueName":"search_term_string"}}],"inLanguage":"en-US"},{"@type":"Person","@id":"https:\/\/xpander.ai\/#\/schema\/person\/a400b76c595b350b1bc258573ffdf6a7","name":"Moriel Pahima","image":{"@type":"ImageObject","inLanguage":"en-US","@id":"https:\/\/xpander.ai\/#\/schema\/person\/image\/","url":"https:\/\/secure.gravatar.com\/avatar\/776a070d09f269ef3d078f9a8041dc92?s=96&d=mm&r=g","contentUrl":"https:\/\/secure.gravatar.com\/avatar\/776a070d09f269ef3d078f9a8041dc92?s=96&d=mm&r=g","caption":"Moriel Pahima"},"description":"Founding Engineer @ xpander.ai","sameAs":["http:\/\/www.xpander.ai"],"url":"https:\/\/xpander.ai\/author\/moriel\/"}]}},"_links":{"self":[{"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/posts\/837"}],"collection":[{"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/users\/7"}],"replies":[{"embeddable":true,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/comments?post=837"}],"version-history":[{"count":24,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/posts\/837\/revisions"}],"predecessor-version":[{"id":881,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/posts\/837\/revisions\/881"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/media\/819"}],"wp:attachment":[{"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/media?parent=837"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/categories?post=837"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/xpander.ai\/wp-json\/wp\/v2\/tags?post=837"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}